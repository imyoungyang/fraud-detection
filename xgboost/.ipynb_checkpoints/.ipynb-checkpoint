{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "  1. [Relative cost of errors](#Relative-cost-of-errors)\n",
    "1. [Extensions](#Extensions)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "\n",
    "Identifying Credit Card fraudelent transaction is crucial to the banking business to protect their customers from fraud. Identifying fraud transactions is not an easy task and it can consume a lot of auditors time to identify those transactions and it can delay the purchasing of whatever items the card holder wants to purchase.\n",
    "\n",
    "In this notebook, I will demonstrate how to build an binary classification model to predict whether a specific credit card transaction is genuine of fraud. I will use Sagemaker's implementation of XGBoost algorithm.\n",
    "\n",
    "\n",
    "\n",
    "## Amazon SageMaker\n",
    "Amazon SageMaker Amazon SageMaker is a fully managed machine learning service that automates the end-to-end ML process. With Amazon SageMaker, data scientists and developers can quickly and easily build and train machine learning models and directly deploy them into a production-ready hosted environment. It provides an integrated Jupyter authoring notebook instance for easy access to your data sources for exploration and analysis, so you don't have to manage servers. It also provides common machine learning algorithms that are optimized to run efficiently against extremely large data in a distributed environment. With native support for bring-your-own-algorithms and frameworks, Amazon SageMaker offers flexible distributed training options that adjust to your specific workflows. Deploy a model into a secure and scalable environment by launching it with a single click from the Amazon SageMaker console. Training and hosting are billed by minutes of usage, with no minimum fees and no upfront commitments. SageMaker python sdk, is a library that provides the user with the ability to wrap your models in helper classes that can be passed to Amazon SageMaker. The python sdk provides you with the ability to use Amazon Algorithms, train and deploy your own code  using Amazon SagedMaker, and bring your own pre-trained dockerized models. Let us next take a look at the architecture of SageMaker. How does Amazon SageMaker Work: Training Training workloads, for an end-to-end model development includes the following components: • S3 Bucket for the training dataset • Amazon SageMaker notebook instance, a fully managed single tenant EC2 instance. • EC2 cluster for training. (fully managed transparent to developer) • S3 bucket for trained model Hosting • S3 bucket for model • ECS infrastructure to host a dockerized model (fully managed transparent to developer) • EC2 cluster manages by ECS • Model Endpoints, elastically scalable callable inference endpoints. (fully managed transparent to developer)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-625616379791\n"
     ]
    }
   ],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "import seaborn as sns\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "#Manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "#manipulating entities and resources that Amazon SageMaker uses, such as training jobs, endpoints, and input datasets in S3.\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'DEMO-xgboost-fraud-detection'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "The dataset we use is publicly available at https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML\n",
    "\n",
    "Please cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2       V3        V4        V5        V6  \\\n",
       "0 0.000000 -1.359807 -0.072781 2.536347  1.378155 -0.338321  0.462388   \n",
       "1 0.000000  1.191857  0.266151 0.166480  0.448154  0.060018 -0.082361   \n",
       "2 1.000000 -1.358354 -1.340163 1.773209  0.379780 -0.503198  1.800499   \n",
       "3 1.000000 -0.966272 -0.185226 1.792993 -0.863291 -0.010309  1.247203   \n",
       "4 2.000000 -1.158233  0.877737 1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9       V10       V11       V12       V13  \\\n",
       "0  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390   \n",
       "1 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095   \n",
       "2  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293   \n",
       "3  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757   \n",
       "4  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852   \n",
       "\n",
       "        V14       V15       V16       V17       V18       V19       V20  \\\n",
       "0 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412   \n",
       "1 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083   \n",
       "2 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980   \n",
       "3 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038   \n",
       "4 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542   \n",
       "\n",
       "        V21       V22       V23       V24       V25       V26       V27  \\\n",
       "0 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558   \n",
       "1 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983   \n",
       "2  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353   \n",
       "3 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723   \n",
       "4 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422   \n",
       "\n",
       "        V28     Amount  Class  \n",
       "0 -0.021053 149.620000      0  \n",
       "1  0.014724   2.690000      0  \n",
       "2 -0.059752 378.660000      0  \n",
       "3  0.061458 123.500000      0  \n",
       "4  0.215153  69.990000      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = pd.read_csv('./creditcard.csv')\n",
    "credit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### 1- Get The Dataframe Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>12.018913</td>\n",
       "      <td>7.848392</td>\n",
       "      <td>7.126883</td>\n",
       "      <td>10.526766</td>\n",
       "      <td>8.877742</td>\n",
       "      <td>17.315112</td>\n",
       "      <td>9.253526</td>\n",
       "      <td>5.041069</td>\n",
       "      <td>5.591971</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean   94813.859575      0.000000      0.000000     -0.000000      0.000000   \n",
       "std    47488.145955      1.958696      1.651309      1.516255      1.415869   \n",
       "min        0.000000    -56.407510    -72.715728    -48.325589     -5.683171   \n",
       "25%    54201.500000     -0.920373     -0.598550     -0.890365     -0.848640   \n",
       "50%    84692.000000      0.018109      0.065486      0.179846     -0.019847   \n",
       "75%   139320.500000      1.315642      0.803724      1.027196      0.743341   \n",
       "max   172792.000000      2.454930     22.057729      9.382558     16.875344   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean      -0.000000      0.000000     -0.000000     -0.000000     -0.000000   \n",
       "std        1.380247      1.332271      1.237094      1.194353      1.098632   \n",
       "min     -113.743307    -26.160506    -43.557242    -73.216718    -13.434066   \n",
       "25%       -0.691597     -0.768296     -0.554076     -0.208630     -0.643098   \n",
       "50%       -0.054336     -0.274187      0.040103      0.022358     -0.051429   \n",
       "75%        0.611926      0.398565      0.570436      0.327346      0.597139   \n",
       "max       34.801666     73.301626    120.589494     20.007208     15.594995   \n",
       "\n",
       "                V10           V11           V12           V13           V14  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000      0.000000      0.000000   \n",
       "std        1.088850      1.020713      0.999201      0.995274      0.958596   \n",
       "min      -24.588262     -4.797473    -18.683715     -5.791881    -19.214325   \n",
       "25%       -0.535426     -0.762494     -0.405571     -0.648539     -0.425574   \n",
       "50%       -0.092917     -0.032757      0.140033     -0.013568      0.050601   \n",
       "75%        0.453923      0.739593      0.618238      0.662505      0.493150   \n",
       "max       23.745136     12.018913      7.848392      7.126883     10.526766   \n",
       "\n",
       "                V15           V16           V17           V18           V19  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000      0.000000      0.000000   \n",
       "std        0.915316      0.876253      0.849337      0.838176      0.814041   \n",
       "min       -4.498945    -14.129855    -25.162799     -9.498746     -7.213527   \n",
       "25%       -0.582884     -0.468037     -0.483748     -0.498850     -0.456299   \n",
       "50%        0.048072      0.066413     -0.065676     -0.003636      0.003735   \n",
       "75%        0.648821      0.523296      0.399675      0.500807      0.458949   \n",
       "max        8.877742     17.315112      9.253526      5.041069      5.591971   \n",
       "\n",
       "                V20           V21           V22           V23           V24  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "std        0.770925      0.734524      0.725702      0.624460      0.605647   \n",
       "min      -54.497720    -34.830382    -10.933144    -44.807735     -2.836627   \n",
       "25%       -0.211721     -0.228395     -0.542350     -0.161846     -0.354586   \n",
       "50%       -0.062481     -0.029450      0.006782     -0.011193      0.040976   \n",
       "75%        0.133041      0.186377      0.528554      0.147642      0.439527   \n",
       "max       39.420904     27.202839     10.503090     22.528412      4.584549   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000     -0.000000     88.349619   \n",
       "std        0.521278      0.482227      0.403632      0.330083    250.120109   \n",
       "min      -10.295397     -2.604551    -22.565679    -15.430084      0.000000   \n",
       "25%       -0.317145     -0.326984     -0.070840     -0.052960      5.600000   \n",
       "50%        0.016594     -0.052139      0.001342      0.011244     22.000000   \n",
       "75%        0.350716      0.240952      0.091045      0.078280     77.165000   \n",
       "max        7.519589      3.517346     31.612198     33.847808  25691.160000   \n",
       "\n",
       "              Class  \n",
       "count 284807.000000  \n",
       "mean       0.001727  \n",
       "std        0.041527  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Checking The Balance of The Data\n",
    "\n",
    "Notice how imbalanced is our original dataset! Most of the transactions are non-fraud. If we use this dataframe as the base for our predictive models and analysis we might get a lot of errors and our algorithms will probably overfit since it will \"assume\" that most transactions are not fraud. But we don't want our model to assume, we want our model to detect patterns that give signs of fraud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Non-Frauds are: 284315 which is  99.83 % of the dataset\n",
      "The number of Frauds are: 492 which is  0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('The number of Non-Frauds are: ' + str(credit_df['Class'].value_counts()[0]) + ' which is ', round(credit_df['Class'].value_counts()[0]/len(credit_df) * 100,2), '% of the dataset')\n",
    "print('The number of Frauds are: ' + str(credit_df['Class'].value_counts()[1]) + ' which is ', round(credit_df['Class'].value_counts()[1]/len(credit_df) * 100,2), '% of the dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ae5157a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class', data=credit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Checking Missing Data\n",
    "\n",
    "If there are any missing data in our dataset, we need to deal with them before training. Data Imputation is a critical step in the Feature Engineering phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Feature Correlation\n",
    "\n",
    "A correlation matrix is a way to show the correlation between different variables in a dataset. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data and find what , as an input into a more advanced analysis\n",
    "\n",
    "**Positive Correlation means:** As feature X increases, feature Y increases and vice versa.\n",
    "\n",
    "**Negative Correlation means:** As feature X go in one direction (Increase), feature Y goes in the other direction (Decrease)\n",
    "\n",
    "Let's plot the first correlation matrix for the imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample figsize in inches\n",
    "fig, ax = plt.subplots(figsize=(20,10))         \n",
    "\n",
    "# Imbalanced DataFrame Correlation\n",
    "corr = credit_df.corr()\n",
    "sns.heatmap(corr, cmap='YlGnBu', annot_kws={'size':30}, ax=ax)\n",
    "ax.set_title(\"Imbalanced Correlation Matrix\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### 1- Fixing The Feature Scaling Problem For (Time and Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "credit_df['scaled_amount'] = rob_scaler.fit_transform(credit_df['Amount'].values.reshape(-1,1))\n",
    "credit_df['scaled_time'] = rob_scaler.fit_transform(credit_df['Time'].values.reshape(-1,1))\n",
    "\n",
    "credit_df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "\n",
    "# Place the class in the begining of the dataframe\n",
    "Class = credit_df['Class']\n",
    "credit_df.drop(['Class'], axis=1, inplace=True)\n",
    "credit_df.insert(0, 'Class', Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.927124</td>\n",
       "      <td>0.118914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.041527</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>3.495006</td>\n",
       "      <td>0.557903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>-0.994983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>-0.229162</td>\n",
       "      <td>-0.358210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>0.770838</td>\n",
       "      <td>0.641790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>12.018913</td>\n",
       "      <td>7.848392</td>\n",
       "      <td>7.126883</td>\n",
       "      <td>10.526766</td>\n",
       "      <td>8.877742</td>\n",
       "      <td>17.315112</td>\n",
       "      <td>9.253526</td>\n",
       "      <td>5.041069</td>\n",
       "      <td>5.591971</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>358.683155</td>\n",
       "      <td>1.035022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Class            V1            V2            V3            V4  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.001727      0.000000      0.000000     -0.000000      0.000000   \n",
       "std        0.041527      1.958696      1.651309      1.516255      1.415869   \n",
       "min        0.000000    -56.407510    -72.715728    -48.325589     -5.683171   \n",
       "25%        0.000000     -0.920373     -0.598550     -0.890365     -0.848640   \n",
       "50%        0.000000      0.018109      0.065486      0.179846     -0.019847   \n",
       "75%        0.000000      1.315642      0.803724      1.027196      0.743341   \n",
       "max        1.000000      2.454930     22.057729      9.382558     16.875344   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean      -0.000000      0.000000     -0.000000     -0.000000     -0.000000   \n",
       "std        1.380247      1.332271      1.237094      1.194353      1.098632   \n",
       "min     -113.743307    -26.160506    -43.557242    -73.216718    -13.434066   \n",
       "25%       -0.691597     -0.768296     -0.554076     -0.208630     -0.643098   \n",
       "50%       -0.054336     -0.274187      0.040103      0.022358     -0.051429   \n",
       "75%        0.611926      0.398565      0.570436      0.327346      0.597139   \n",
       "max       34.801666     73.301626    120.589494     20.007208     15.594995   \n",
       "\n",
       "                V10           V11           V12           V13           V14  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000      0.000000      0.000000   \n",
       "std        1.088850      1.020713      0.999201      0.995274      0.958596   \n",
       "min      -24.588262     -4.797473    -18.683715     -5.791881    -19.214325   \n",
       "25%       -0.535426     -0.762494     -0.405571     -0.648539     -0.425574   \n",
       "50%       -0.092917     -0.032757      0.140033     -0.013568      0.050601   \n",
       "75%        0.453923      0.739593      0.618238      0.662505      0.493150   \n",
       "max       23.745136     12.018913      7.848392      7.126883     10.526766   \n",
       "\n",
       "                V15           V16           V17           V18           V19  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000      0.000000      0.000000   \n",
       "std        0.915316      0.876253      0.849337      0.838176      0.814041   \n",
       "min       -4.498945    -14.129855    -25.162799     -9.498746     -7.213527   \n",
       "25%       -0.582884     -0.468037     -0.483748     -0.498850     -0.456299   \n",
       "50%        0.048072      0.066413     -0.065676     -0.003636      0.003735   \n",
       "75%        0.648821      0.523296      0.399675      0.500807      0.458949   \n",
       "max        8.877742     17.315112      9.253526      5.041069      5.591971   \n",
       "\n",
       "                V20           V21           V22           V23           V24  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "std        0.770925      0.734524      0.725702      0.624460      0.605647   \n",
       "min      -54.497720    -34.830382    -10.933144    -44.807735     -2.836627   \n",
       "25%       -0.211721     -0.228395     -0.542350     -0.161846     -0.354586   \n",
       "50%       -0.062481     -0.029450      0.006782     -0.011193      0.040976   \n",
       "75%        0.133041      0.186377      0.528554      0.147642      0.439527   \n",
       "max       39.420904     27.202839     10.503090     22.528412      4.584549   \n",
       "\n",
       "                V25           V26           V27           V28  scaled_amount  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000  284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000     -0.000000       0.927124   \n",
       "std        0.521278      0.482227      0.403632      0.330083       3.495006   \n",
       "min      -10.295397     -2.604551    -22.565679    -15.430084      -0.307413   \n",
       "25%       -0.317145     -0.326984     -0.070840     -0.052960      -0.229162   \n",
       "50%        0.016594     -0.052139      0.001342      0.011244       0.000000   \n",
       "75%        0.350716      0.240952      0.091045      0.078280       0.770838   \n",
       "max        7.519589      3.517346     31.612198     33.847808     358.683155   \n",
       "\n",
       "        scaled_time  \n",
       "count 284807.000000  \n",
       "mean       0.118914  \n",
       "std        0.557903  \n",
       "min       -0.994983  \n",
       "25%       -0.358210  \n",
       "50%        0.000000  \n",
       "75%        0.641790  \n",
       "max        1.035022  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see immediately that:\n",
    "- `time_after_scaling` appears to be quite evenly distributed and scaled with min and max values are within the range of the other features\n",
    "- `amount_after_scaling` transaction amount values are also scaled to be within the range of the other features with min of -0.307 and max of 358.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Fix the target feature imbalance problem (Resampling)\n",
    "\n",
    "<img src=\"./resampling.png\">\n",
    "\n",
    "#### Undersampling The Class Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the Dataset.\n",
    "shuffled_df = credit_df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = shuffled_df.loc[shuffled_df['Class'] == 1]\n",
    "\n",
    "#Randomly select 492 observations.\n",
    "non_fraud_df = shuffled_df.loc[shuffled_df['Class'] == 0].sample(n=492)\n",
    "normalized_df = pd.concat([fraud_df, non_fraud_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class', data=normalized_df)\n",
    "plt.title('Balanced Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the normalized dataset before splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276839</th>\n",
       "      <td>0</td>\n",
       "      <td>1.988976</td>\n",
       "      <td>0.152075</td>\n",
       "      <td>-1.721576</td>\n",
       "      <td>0.559875</td>\n",
       "      <td>0.176754</td>\n",
       "      <td>-1.502428</td>\n",
       "      <td>0.367936</td>\n",
       "      <td>-0.444919</td>\n",
       "      <td>0.482977</td>\n",
       "      <td>-0.508305</td>\n",
       "      <td>-0.224355</td>\n",
       "      <td>0.431369</td>\n",
       "      <td>0.684093</td>\n",
       "      <td>-0.856023</td>\n",
       "      <td>0.826606</td>\n",
       "      <td>0.172494</td>\n",
       "      <td>0.361865</td>\n",
       "      <td>0.420144</td>\n",
       "      <td>-0.451801</td>\n",
       "      <td>-0.091169</td>\n",
       "      <td>0.225404</td>\n",
       "      <td>0.780418</td>\n",
       "      <td>-0.058630</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.262236</td>\n",
       "      <td>-0.110064</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>-0.023412</td>\n",
       "      <td>0.234053</td>\n",
       "      <td>0.970794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70141</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.649279</td>\n",
       "      <td>1.263974</td>\n",
       "      <td>-1.050826</td>\n",
       "      <td>2.237991</td>\n",
       "      <td>-2.527889</td>\n",
       "      <td>-0.889940</td>\n",
       "      <td>-2.355254</td>\n",
       "      <td>0.854659</td>\n",
       "      <td>-1.281243</td>\n",
       "      <td>-2.705011</td>\n",
       "      <td>1.174475</td>\n",
       "      <td>-4.381920</td>\n",
       "      <td>-1.226666</td>\n",
       "      <td>-2.953824</td>\n",
       "      <td>1.994161</td>\n",
       "      <td>-3.304254</td>\n",
       "      <td>-5.585794</td>\n",
       "      <td>-1.643704</td>\n",
       "      <td>2.118633</td>\n",
       "      <td>0.087406</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>0.731907</td>\n",
       "      <td>0.333045</td>\n",
       "      <td>0.392505</td>\n",
       "      <td>-0.274197</td>\n",
       "      <td>0.802349</td>\n",
       "      <td>0.390809</td>\n",
       "      <td>0.112146</td>\n",
       "      <td>1.263886</td>\n",
       "      <td>-0.363785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42741</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.001351</td>\n",
       "      <td>6.613284</td>\n",
       "      <td>-12.423635</td>\n",
       "      <td>7.519929</td>\n",
       "      <td>-10.266255</td>\n",
       "      <td>-2.113208</td>\n",
       "      <td>-9.984287</td>\n",
       "      <td>5.541941</td>\n",
       "      <td>-7.383705</td>\n",
       "      <td>-13.215172</td>\n",
       "      <td>6.895181</td>\n",
       "      <td>-13.279700</td>\n",
       "      <td>0.755264</td>\n",
       "      <td>-13.417012</td>\n",
       "      <td>-0.210774</td>\n",
       "      <td>-10.922655</td>\n",
       "      <td>-21.906493</td>\n",
       "      <td>-8.829820</td>\n",
       "      <td>1.852467</td>\n",
       "      <td>-0.645394</td>\n",
       "      <td>1.775891</td>\n",
       "      <td>-1.224758</td>\n",
       "      <td>0.082594</td>\n",
       "      <td>0.452089</td>\n",
       "      <td>0.463827</td>\n",
       "      <td>-0.296928</td>\n",
       "      <td>0.526506</td>\n",
       "      <td>-0.450890</td>\n",
       "      <td>6.107315</td>\n",
       "      <td>-0.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190774</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.682184</td>\n",
       "      <td>-1.148645</td>\n",
       "      <td>1.258870</td>\n",
       "      <td>-2.531184</td>\n",
       "      <td>1.228326</td>\n",
       "      <td>1.691466</td>\n",
       "      <td>0.246707</td>\n",
       "      <td>-0.045485</td>\n",
       "      <td>-0.040970</td>\n",
       "      <td>1.026738</td>\n",
       "      <td>1.166573</td>\n",
       "      <td>-0.389682</td>\n",
       "      <td>-0.593873</td>\n",
       "      <td>-1.121794</td>\n",
       "      <td>-0.541385</td>\n",
       "      <td>0.387883</td>\n",
       "      <td>0.328289</td>\n",
       "      <td>-2.632607</td>\n",
       "      <td>-0.184343</td>\n",
       "      <td>-0.569102</td>\n",
       "      <td>-0.426963</td>\n",
       "      <td>-0.276193</td>\n",
       "      <td>0.409113</td>\n",
       "      <td>-0.777018</td>\n",
       "      <td>0.354082</td>\n",
       "      <td>-0.553396</td>\n",
       "      <td>-1.074592</td>\n",
       "      <td>0.360989</td>\n",
       "      <td>0.111786</td>\n",
       "      <td>0.520295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30473</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.194074</td>\n",
       "      <td>4.382897</td>\n",
       "      <td>-5.118363</td>\n",
       "      <td>4.455230</td>\n",
       "      <td>-4.812621</td>\n",
       "      <td>-1.224645</td>\n",
       "      <td>-7.281328</td>\n",
       "      <td>3.332250</td>\n",
       "      <td>-3.679659</td>\n",
       "      <td>-7.524368</td>\n",
       "      <td>2.954344</td>\n",
       "      <td>-7.099825</td>\n",
       "      <td>1.520369</td>\n",
       "      <td>-7.687803</td>\n",
       "      <td>-0.225002</td>\n",
       "      <td>-8.520850</td>\n",
       "      <td>-13.277300</td>\n",
       "      <td>-5.253705</td>\n",
       "      <td>3.623332</td>\n",
       "      <td>0.579098</td>\n",
       "      <td>1.550473</td>\n",
       "      <td>0.614573</td>\n",
       "      <td>0.028521</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>-0.149512</td>\n",
       "      <td>-0.131687</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>0.473757</td>\n",
       "      <td>-0.105359</td>\n",
       "      <td>-0.572728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class        V1        V2         V3        V4         V5        V6  \\\n",
       "276839      0  1.988976  0.152075  -1.721576  0.559875   0.176754 -1.502428   \n",
       "70141       1 -1.649279  1.263974  -1.050826  2.237991  -2.527889 -0.889940   \n",
       "42741       1 -9.001351  6.613284 -12.423635  7.519929 -10.266255 -2.113208   \n",
       "190774      0 -2.682184 -1.148645   1.258870 -2.531184   1.228326  1.691466   \n",
       "30473       1 -4.194074  4.382897  -5.118363  4.455230  -4.812621 -1.224645   \n",
       "\n",
       "              V7        V8        V9        V10       V11        V12  \\\n",
       "276839  0.367936 -0.444919  0.482977  -0.508305 -0.224355   0.431369   \n",
       "70141  -2.355254  0.854659 -1.281243  -2.705011  1.174475  -4.381920   \n",
       "42741  -9.984287  5.541941 -7.383705 -13.215172  6.895181 -13.279700   \n",
       "190774  0.246707 -0.045485 -0.040970   1.026738  1.166573  -0.389682   \n",
       "30473  -7.281328  3.332250 -3.679659  -7.524368  2.954344  -7.099825   \n",
       "\n",
       "             V13        V14       V15        V16        V17       V18  \\\n",
       "276839  0.684093  -0.856023  0.826606   0.172494   0.361865  0.420144   \n",
       "70141  -1.226666  -2.953824  1.994161  -3.304254  -5.585794 -1.643704   \n",
       "42741   0.755264 -13.417012 -0.210774 -10.922655 -21.906493 -8.829820   \n",
       "190774 -0.593873  -1.121794 -0.541385   0.387883   0.328289 -2.632607   \n",
       "30473   1.520369  -7.687803 -0.225002  -8.520850 -13.277300 -5.253705   \n",
       "\n",
       "             V19       V20       V21       V22       V23       V24       V25  \\\n",
       "276839 -0.451801 -0.091169  0.225404  0.780418 -0.058630  0.003099  0.262236   \n",
       "70141   2.118633  0.087406  0.679176  0.731907  0.333045  0.392505 -0.274197   \n",
       "42741   1.852467 -0.645394  1.775891 -1.224758  0.082594  0.452089  0.463827   \n",
       "190774 -0.184343 -0.569102 -0.426963 -0.276193  0.409113 -0.777018  0.354082   \n",
       "30473   3.623332  0.579098  1.550473  0.614573  0.028521  0.013704 -0.149512   \n",
       "\n",
       "             V26       V27       V28  scaled_amount  scaled_time  \n",
       "276839 -0.110064 -0.004550 -0.023412       0.234053     0.970794  \n",
       "70141   0.802349  0.390809  0.112146       1.263886    -0.363785  \n",
       "42741  -0.296928  0.526506 -0.450890       6.107315    -0.510638  \n",
       "190774 -0.553396 -1.074592  0.360989       0.111786     0.520295  \n",
       "30473  -0.131687  0.473934  0.473757      -0.105359    -0.572728  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_normalized_df = normalized_df.sample(frac=1)\n",
    "shuffled_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(shuffled_normalized_df, [int(0.7 * len(shuffled_normalized_df)), int(0.9 * len(shuffled_normalized_df))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Moving onto training, first we'll need to specify the locations of the XGBoost algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:1'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can specify a few parameters like what type of training instances we'd like to use and how many, as well as our XGBoost hyperparameters.  A few key hyperparameters are:\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "Binary classification error rate. It is calculated as #(wrong cases)/#(all cases)\n",
    "\n",
    "\n",
    "More detail on XGBoost's hyperparmeters can be found on their GitHub [page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-2019-02-11-09-26-24-447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-11 09:26:24 Starting - Starting the training job...\n",
      "2019-02-11 09:26:26 Starting - Launching requested ML instances......\n",
      "2019-02-11 09:27:33 Starting - Preparing the instances for training......\n",
      "2019-02-11 09:28:37 Downloading - Downloading input data..\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-02-11:09:29:03:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-02-11:09:29:03:INFO] File size need to be processed in the node: 0.48mb. Available memory size in the node: 8423.25mb\u001b[0m\n",
      "\u001b[31m[2019-02-11:09:29:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[09:29:03] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[09:29:03] 688x30 matrix with 20640 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-02-11:09:29:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[09:29:03] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[09:29:03] 197x30 matrix with 5910 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[0]#011train-error:0.074128#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[1]#011train-error:0.074128#011validation-error:0.081218\u001b[0m\n",
      "\u001b[31m[2]#011train-error:0.056686#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[3]#011train-error:0.055233#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[4]#011train-error:0.055233#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[5]#011train-error:0.052326#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[6]#011train-error:0.049419#011validation-error:0.045685\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[7]#011train-error:0.049419#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[8]#011train-error:0.046512#011validation-error:0.050761\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[9]#011train-error:0.046512#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[10]#011train-error:0.045058#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[11]#011train-error:0.045058#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[12]#011train-error:0.043605#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[13]#011train-error:0.045058#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[14]#011train-error:0.045058#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[15]#011train-error:0.042151#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[16]#011train-error:0.039244#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[17]#011train-error:0.039244#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[18]#011train-error:0.039244#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[19]#011train-error:0.036337#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[20]#011train-error:0.034884#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[21]#011train-error:0.037791#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[22]#011train-error:0.03343#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[23]#011train-error:0.034884#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[24]#011train-error:0.03343#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[25]#011train-error:0.031977#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[26]#011train-error:0.02907#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[27]#011train-error:0.03343#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[28]#011train-error:0.03343#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[29]#011train-error:0.027616#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[30]#011train-error:0.027616#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[31]#011train-error:0.027616#011validation-error:0.055838\u001b[0m\n",
      "\u001b[31m[32]#011train-error:0.030523#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[33]#011train-error:0.030523#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[34]#011train-error:0.030523#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[35]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[36]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[37]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[38]#011train-error:0.030523#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[39]#011train-error:0.030523#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[40]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[41]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[42]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[43]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[44]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[45]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[46]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[47]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[48]#011train-error:0.02907#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[49]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[50]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[51]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[52]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[53]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[54]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[55]#011train-error:0.02907#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[56]#011train-error:0.030523#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[57]#011train-error:0.026163#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[58]#011train-error:0.026163#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[59]#011train-error:0.027616#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[60]#011train-error:0.027616#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[61]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[62]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[63]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[64]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[65]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[66]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[67]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[68]#011train-error:0.026163#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[69]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[70]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[71]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[72]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[73]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[74]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[75]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[76]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[77]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[78]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[79]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[80]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[81]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[82]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[83]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[84]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[85]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[86]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[87]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[88]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[89]#011train-error:0.026163#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[90]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[91]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[92]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[93]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[94]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[95]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[96]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[97]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[98]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[99]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[100]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[101]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[102]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[103]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[104]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[105]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[106]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[107]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[108]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[109]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[110]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[111]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[112]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[113]#011train-error:0.024709#011validation-error:0.060914\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[114]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[115]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[116]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[117]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[118]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[119]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[120]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[121]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[122]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[123]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[124]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[125]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[126]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[127]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[128]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[129]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[130]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[131]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[132]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[133]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[134]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[135]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[136]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[137]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[138]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[139]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[140]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[141]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[142]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[143]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[144]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[145]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[146]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[147]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[148]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[149]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[150]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[151]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[152]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[153]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[154]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[155]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[156]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[157]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[158]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[159]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[160]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[161]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[162]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[163]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[164]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[165]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[166]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[167]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[168]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[169]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[170]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[171]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[172]#011train-error:0.026163#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[173]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[174]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[175]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[176]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[177]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[178]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[179]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[180]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[181]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[182]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[183]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[184]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[185]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[186]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[187]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[188]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[189]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[190]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[191]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[192]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[193]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[194]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[195]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[196]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[197]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[198]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[199]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[200]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[201]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[202]#011train-error:0.024709#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[203]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[204]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[205]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[206]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[207]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[208]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[209]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[210]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[211]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[212]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[213]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[214]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[215]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[216]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[217]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[218]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[219]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[220]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[221]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[222]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[223]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[224]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[225]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[226]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[227]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[228]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[229]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[230]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[231]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[232]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[233]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[234]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[235]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[236]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[237]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[238]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[239]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[240]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[241]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[242]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[243]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[244]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[245]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[246]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[247]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[248]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[249]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[250]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[251]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[252]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[253]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[254]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[255]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[256]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[257]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[258]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[259]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[260]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[261]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[262]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[263]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[264]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[265]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[266]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[267]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[268]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[269]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[270]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[271]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[272]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[273]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[274]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[275]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[276]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[277]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[278]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[279]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[280]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[281]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[282]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[283]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[284]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[285]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[286]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[287]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[288]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[289]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[290]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[291]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[292]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[293]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[294]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[295]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[296]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[297]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[298]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[299]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[300]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[301]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[302]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[303]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[304]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[305]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[306]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[307]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[308]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[309]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[310]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[311]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[312]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[313]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[314]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[315]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[316]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[317]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[318]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[319]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[320]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[321]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[322]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[323]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[324]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[325]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[326]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[327]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[328]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[329]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[330]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[331]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[332]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[333]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[334]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[335]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[336]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[337]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[338]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[339]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[340]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[341]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[342]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[343]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[344]#011train-error:0.021802#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[345]#011train-error:0.023256#011validation-error:0.071066\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[346]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[347]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[348]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[349]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[350]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[351]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[352]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[353]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[354]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[355]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[356]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[357]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[358]#011train-error:0.021802#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[359]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[360]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[361]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[362]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[363]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[364]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[365]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[366]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[367]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[368]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[369]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[370]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[371]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[372]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[373]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[374]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[375]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[376]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[377]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[378]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[379]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[380]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[381]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[382]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[383]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[384]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[385]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[386]#011train-error:0.023256#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[387]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[388]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[389]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[390]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[391]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[392]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[393]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[394]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[395]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[396]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[397]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[398]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n",
      "\u001b[31m[09:29:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[399]#011train-error:0.024709#011validation-error:0.06599\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-02-11 09:29:15 Training - Training image download completed. Training in progress.\n",
      "2019-02-11 09:29:15 Uploading - Uploading generated training model\n",
      "2019-02-11 09:29:15 Completed - Training job completed\n",
      "Billable seconds: 38\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=400)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the algorithm, let's create a model and deploy it to a hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-2019-02-11-09-30-51-324\n",
      "INFO:sagemaker:Creating endpoint with name xgboost-2019-02-11-09-26-24-447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request.  But first, we'll need to setup serializers and deserializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batchs to CSV string payloads\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.as_matrix()[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to compare the performance of a machine learning model, but let's start by simply by comparing actual to predicted values.  In this case, we're simply predicting whether the credit card transaction is Fraud (`1`) or not (`0`), which produces a simple confusion matrix.\n",
    "\n",
    "#### Print Confusion Matrix\n",
    "<img src=\"./Confusion_matrix.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions  0.000000  1.000000\n",
       "actual                         \n",
       "0                  61         2\n",
       "1                   4        32"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note, due to randomized elements of the algorithm, you results may differ slightly._\n",
    "\n",
    "Of the 48 churners, we've correctly predicted 39 of them (true positives). And, we incorrectly predicted 4 customers would churn who then ended up not doing so (false positives).  There are also 9 customers who ended up churning, that we predicted would not (false negatives).\n",
    "\n",
    "An important point here is that because of the `np.round()` function above we are using a simple threshold (or cutoff) of 0.5.  Our predictions from `xgboost` come out as continuous values between 0 and 1 and we force them into the binary classes that we began with.  However, because a customer that churns is expected to cost the company more than proactively trying to retain a customer who we think might churn, we should consider adjusting this cutoff.  That will almost certainly increase the number of false positives, but it can also be expected to increase the number of true positives and reduce the number of false negatives.\n",
    "\n",
    "To get a rough intuition here, let's look at the continuous values of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous valued predictions coming from our model tend to skew toward 0 or 1, but there is sufficient mass between 0.1 and 0.9 that adjusting the cutoff should indeed shift a number of customers' predictions.  For example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "Class        \n",
       "0      59   4\n",
       "1       3  33"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.where(predictions > 0.3, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing the cutoff from 0.5 to 0.3 results in 1 more true positives, 3 more false positives, and 1 fewer false negatives.  The numbers are small overall here, but that's 6-10% of customers overall that are shifting because of a change to the cutoff.  Was this the right decision?  We may end up retaining 3 extra customers, but we also unnecessarily incentivized 5 more customers who would have stayed.  Determining optimal cutoffs is a key step in properly applying machine learning in a real-world setting.  Let's discuss this more broadly and then apply a specific, hypothetical solution for our current problem.\n",
    "\n",
    "### Relative cost of errors\n",
    "\n",
    "Any practical binary classification problem is likely to produce a similarly sensitive cutoff. That by itself isn’t a problem. After all, if the scores for two classes are really easy to separate, the problem probably isn’t very hard to begin with and might even be solvable with simple rules instead of ML.\n",
    "\n",
    "More important, if I put an ML model into production, there are costs associated with the model erroneously assigning false positives and false negatives. I also need to look at similar costs associated with correct predictions of true positives and true negatives.  Because the choice of the cutoff affects all four of these statistics, I need to consider the relative costs to the business for each of these four outcomes for each prediction.\n",
    "\n",
    "#### Assigning costs\n",
    "\n",
    "What are the costs for our problem of mobile operator churn? The costs, of course, depend on the specific actions that the business takes. Let's make some assumptions here.\n",
    "\n",
    "First, assign the true negatives the cost of \\$0. Our model essentially correctly identified a happy customer in this case, and we don’t need to do anything.\n",
    "\n",
    "False negatives are the most problematic, because they incorrectly predict that a churning customer will stay. We lose the customer and will have to pay all the costs of acquiring a replacement customer, including foregone revenue, advertising costs, administrative costs, point of sale costs, and likely a phone hardware subsidy. A quick search on the Internet reveals that such costs typically run in the hundreds of dollars so, for the purposes of this example, let's assume \\$500. This is the cost of false negatives.\n",
    "\n",
    "Finally, for customers that our model identifies as churning, let's assume a retention incentive in the amount of \\\\$100. If my provider offered me such a concession, I’d certainly think twice before leaving. This is the cost of both true positive and false positive outcomes. In the case of false positives (the customer is happy, but the model mistakenly predicted churn), we will “waste” the \\\\$100 concession. We probably could have spent that \\\\$100 more effectively, but it's possible we increased the loyalty of an already loyal customer, so that’s not so bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the optimal cutoff\n",
    "\n",
    "It’s clear that false negatives are substantially more costly than false positives. Instead of optimizing for error based on the number of customers, we should be minimizing a cost function that looks like this:\n",
    "\n",
    "```txt\n",
    "$500 * FN(C) + $0 * TN(C) + $100 * FP(C) + $100 * TP(C)\n",
    "```\n",
    "\n",
    "FN(C) means that the false negative percentage is a function of the cutoff, C, and similar for TN, FP, and TP.  We need to find the cutoff, C, where the result of the expression is smallest.\n",
    "\n",
    "A straightforward way to do this, is to simply run a simulation over a large number of possible cutoffs.  We test 100 possible values in the for loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.arange(0.01, 1, 0.01)\n",
    "costs = []\n",
    "for c in cutoffs:\n",
    "    costs.append(np.sum(np.sum(np.array([[0, 100], [500, 100]]) * \n",
    "                               pd.crosstab(index=test_data.iloc[:, 0], \n",
    "                                           columns=np.where(predictions > c, 1, 0)))))\n",
    "\n",
    "costs = np.array(costs)\n",
    "plt.plot(cutoffs, costs)\n",
    "plt.show()\n",
    "print('Cost is minimized near a cutoff of:', cutoffs[np.argmin(costs)], 'for a cost of:', np.min(costs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows how picking a threshold too low results in costs skyrocketing as all customers are given a retention incentive.  Meanwhile, setting the threshold too high results in too many lost customers, which ultimately grows to be nearly as costly.  The overall cost can be minimized at \\\\$ 8400 by setting the cutoff to 0.46, which is substantially better than the\n",
    "\\\\$ 20k+ I would expect to lose by not taking any action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions\n",
    "\n",
    "This notebook showcased how to build a model that predicts whether a customer is likely to churn, and then how to optimally set a threshold that accounts for the cost of true positives, false positives, and false negatives.  There are several means of extending it including:\n",
    "- Some customers who receive retention incentives will still churn.  Including a probability of churning despite receiving an incentive in our cost function would provide a better ROI on our retention programs.\n",
    "- Customers who switch to a lower-priced plan or who deactivate a paid feature represent different kinds of churn that could be modeled separately.\n",
    "- Modeling the evolution of customer behavior. If usage is dropping and the number of calls placed to Customer Service is increasing, you are more likely to experience churn then if the trend is the opposite. A customer profile should incorporate behavior trends.\n",
    "- Actual training data and monetary cost assignments could be more complex.\n",
    "- Multiple models for each type of churn could be needed.\n",
    "\n",
    "Regardless of additional complexity, similar principles described in this notebook are likely apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing model for prediction using Neo API\n",
    "Neo API allows to optimize our model for a specific hardware type. When calling `compile_model()` function, we specify the target instance family (C5) as well as the S3 bucket to which the compiled model would be stored.\n",
    "\n",
    "**Important. If the following command result in a permission error, scroll up and locate the value of execution role returned by `get_execution_role()`. The role must have access to the S3 bucket specified in ``output_path``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/'.join(xgb.output_path.split('/')[:-1])\n",
    "compiled_model = xgb.compile_model(target_instance_family='ml_c5', \n",
    "                                   input_shape={'data':[1, 69]},\n",
    "                                   role=role,\n",
    "                                   framework='xgboost',\n",
    "                                   framework_version='0.7',\n",
    "                                   output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an inference Endpoint\n",
    "\n",
    "We can deploy this compiled model, note that we need to use the same instance that the target we used for compilation. This creates a SageMaker endpoint that we can use to perform inference. \n",
    "\n",
    "The arguments to the ``deploy`` function allow us to set the number and type of instances that will be used for the Endpoint. Make sure to choose an instance for which you have compiled your model, so in our case  `ml_c5`. Neo API uses a special runtime (DLR runtime), in which our optimzed model will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known issue: need to manually specify endpoint name\n",
    "compiled_model.name = 'deployed-xgboost-customer-churn'\n",
    "# There is a known issue where SageMaker SDK locates the incorrect docker image URI for XGBoost\n",
    "# For now, we manually set Image URI\n",
    "compiled_model.image = get_image_uri(sess.boto_region_name, 'xgboost-neo', repo_version='latest')\n",
    "compiled_predictor = compiled_model.deploy(initial_instance_count = 1, instance_type = 'ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an inference request\n",
    "The compiled model accepts CSV content type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictor.content_type = 'text/csv'\n",
    "compiled_predictor.serializer = csv_serializer\n",
    "compiled_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, compiled_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "# Batch prediction is not supported yet; need to send one data point at a time\n",
    "dtest = test_data.as_matrix()\n",
    "predictions = []\n",
    "for i in range(dtest.shape[0]):\n",
    "    predictions.append(optimized_predict(dtest[i:i+1, 1:]))\n",
    "predictions = np.array(predictions).squeeze()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean-up\n",
    "\n",
    "If you're ready to be done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "sagemaker.Session().delete_endpoint(compiled_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.rand(7, 10)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "test = \"0.0,-1.359807,-0.072781,2.536347,1.378155,-0.338321,0.462388,0.239599,0.098698,0.363787,0.090794,-0.551600,-0.617801,-0.991390,-0.311169,1.468177,-0.470401,0.207971,0.025791,0.403993,0.251412,-0.018307,0.277838,-0.110474,0.066928,0.128539,-0.189115,0.133558,-0.021053,149.62\".split(',')\n",
    "data = np.asarray(test).reshape((1,-1))\n",
    "test_matrix = xgb.DMatrix(data)\n",
    "filename = \"./xgboost-model\"\n",
    "xgb_loaded = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_loaded.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338594"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-e9f6cfca35ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#xgb.Booster(model_file=\"./xgboost-model\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_loaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import plot_tree, Booster\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from xgboost import plot_tree, plot_importance\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "# plot single tree\n",
    "rcParams['figure.figsize'] = 50,50\n",
    " \n",
    "model = pkl.load(open(filename,'rb')) \n",
    "#xgb.Booster(model_file=\"./xgboost-model\")\n",
    "plot_tree(xgb_loaded, num_trees=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n",
      "Train: [265518 180305  42664 ...  29062  13766  17677] Test: [263020  11378 147283 ... 274532 269819  64170]\n",
      "Train: [ 72227 114282  16818 ... 264471 191914 284017] Test: [202638  32978 128121 ... 244024 127667  48318]\n",
      "Train: [ 20895 114622 167683 ... 244502 178972 218506] Test: [284352  82483  90981 ... 171224 168807 271602]\n",
      "Train: [122248 181660 194400 ... 104631 277586  29432] Test: [225673  63348  68025 ... 279451  77554  76043]\n",
      "Train: [241684 223467 136928 ...  86495 160550  49633] Test: [157557 204860  83760 ... 251478 178967 216850]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827075 0.00172925]\n",
      "[0.99827955 0.00172045]\n",
      "Length of X (train): 227845 | Length of y (train): 227845\n",
      "Length of X (test): 56962 | Length of y (test): 56962\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "accuracy: 0.9932322412166166\n",
      "precision: 0.18780542984548032\n",
      "recall: 0.8481012658227849\n",
      "f1: 0.306691937316803\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "print('No Frauds', round(credit_df['Class'].value_counts()[0]/len(credit_df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(credit_df['Class'].value_counts()[1]/len(credit_df) * 100,2), '% of the dataset')\n",
    "\n",
    "X = credit_df.drop('Class', axis=1)\n",
    "y = credit_df['Class']\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n",
    "# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "\n",
    "\n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))\n",
    "\n",
    "\n",
    "print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n",
    "print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n",
    "\n",
    "# List to append the score and then find the average\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "# Classifier with optimal parameters\n",
    "# log_reg_sm = grid_log_reg.best_estimator_\n",
    "log_reg_sm = LogisticRegression()\n",
    "\n",
    "\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n",
    "\n",
    "\n",
    "# Implementing SMOTE Technique \n",
    "# Cross Validating the right way\n",
    "# Parameters\n",
    "for train, test in sss.split(original_Xtrain, original_ytrain):\n",
    "    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(original_Xtrain[test])\n",
    "    \n",
    "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
    "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
    "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
    "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
    "    \n",
    "print('---' * 45)\n",
    "print('')\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE Technique (OverSampling) After splitting and Cross Validating\n",
    "sm = SMOTE(ratio='minority', random_state=42)\n",
    "# Xsm_train, ysm_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "# This will be the data were we are going to \n",
    "Xsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "unique, counts = numpy.unique(ysm_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227451, 227451])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454902, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(Xsm_train)\n",
    "x_train.insert(0, 'Class', ysm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(x_train.sample(frac=1), [int(0.7 * len(x_train.sample(frac=1))), int(0.9 * len(x_train.sample(frac=1)))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
